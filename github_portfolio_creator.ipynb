{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('OPENAI_API_KEY')\n",
    "api_key=os.getenv('OPENAI_API_KEY')\n",
    "MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64; rv:133.0) Gecko/20100101 Firefox/133.0\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class website:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        \n",
    "        # Handle title\n",
    "        self.title = soup.title.string if soup.title else \"no title found\"\n",
    "        \n",
    "        # Handle body text\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        \n",
    "        # Handle links\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "        \n",
    "        # Handle about section - with error handling\n",
    "        about_element = soup.find('p', class_=['f4', 'my-3'])\n",
    "        self.about = about_element.get_text(separator=\"\\n\", strip=True) if about_element else \"\"\n",
    "        \n",
    "        # Handle readme - with error handling\n",
    "        readme_element = soup.find('article', class_=['markdown-body', 'entry-content container-lg'])\n",
    "        self.readme = readme_element.get_text(separator=\"\\n\", strip=True) if readme_element else \"\"\n",
    "        \n",
    "        # Handle project title - with error handling\n",
    "        project_title_element = soup.find('a', class_=['d-block', 'overflow-x-hidden', 'color-fg-default'])\n",
    "        self.project_title = project_title_element.text if project_title_element else \"\"\n",
    "\n",
    "        name=soup.find('span', attrs={'itemprop': 'name'})\n",
    "        self.name=name.text.strip() if name else \"\"\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.name}\\nWebpage Contents:\\n{self.text}\\n\\n\"\n",
    "\n",
    "    def get_project_details(self):\n",
    "        return f\"\\nAbout:\\n{self.about}\\n\\nReadmefile content:\\n{self.readme}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are provided with a list of links found on a GitHub profile page. You are able to identify which links are repositories/projects created by the user, excluding forked repositories or links to other GitHub features.\n",
      "You should respond in JSON as in this example:\n",
      "{\n",
      "\"repositories\": [\n",
      "    {\"type\": \"project name\", \"url\": \"https://github.com/username/project-name\"},\n",
      "    {\"type\": \"another project\", \"url\": \"https://github.com/username/another-project\"}\n",
      "]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a GitHub profile page. \\\n",
    "You are able to identify which links are repositories/projects created by the user, \\\n",
    "excluding forked repositories or links to other GitHub features.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "\"repositories\": [\n",
    "    {\"type\": \"project name\", \"url\": \"https://github.com/username/project-name\"},\n",
    "    {\"type\": \"another project\", \"url\": \"https://github.com/username/another-project\"}\n",
    "]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(link_system_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links from the GitHub profile {website.url} - \"\n",
    "    user_prompt += \"please identify which repositories/projects were created by this user. \\\n",
    "    Exclude forked repositories, social media links, following/follower links, and other GitHub navigation links. \\\n",
    "    Respond with the full https URL in JSON format.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    Website=website(url)\n",
    "    response=openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\":link_system_prompt},\n",
    "            {\"role\":\"user\",\"content\":link_user_prompt(Website)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result=response.choices[0].message.content\n",
    "\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    data=website(url)\n",
    "    result=\"Github Profile Page:\\n\"\n",
    "    result+=data.get_contents()\n",
    "    result+=\"\\n\\nName of User:\\n\\n\"\n",
    "    result+=data.name\n",
    "    links=get_links(url)\n",
    "    # print(\"Found projects:\", links)\n",
    "\n",
    "    result+=\"\\n\\n Project lists:\\n\\n\"\n",
    "    for link in links[\"repositories\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += website(link[\"url\"]).get_project_details()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a professional portfolio creation assistant that analyzes GitHub profile 'About' sections \\\n",
    "and README.md files to craft compelling developer portfolios. Your task is to examine:\n",
    "\n",
    "- Profile bio and personal description\n",
    "- Highlighted skills and technologies\n",
    "- Featured repositories and pinned projects\n",
    "- Professional goals and interests\n",
    "- README content including personal introductions\n",
    "- Contact information and professional links\n",
    "\n",
    "Create a polished portfolio in markdown that effectively presents:\n",
    "1. Professional summary and career objectives\n",
    "2. Core technical competencies and specializations\n",
    "3. Notable projects and achievements\n",
    "4. Professional interests and development focus\n",
    "5. Professional contact methods and social links\n",
    "\n",
    "Structure the content to create an engaging narrative that resonates with technical recruiters \\\n",
    "while maintaining the developer's authentic voice and professional brand.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_user_prompt(url):\n",
    "    user_prompt = f\"You are analyzing {website(url).name}'s GitHub profile\\n\"\n",
    "    user_prompt += \"Based on their About section and README.md content of projects, create a professional portfolio in markdown that showcases their expertise.\\n\"\n",
    "    user_prompt += \"Here is their profile information along with project details:\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:15_000]  # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_portfolio(url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": portfolio_user_prompt(url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Andrej's Developer Portfolio\n",
       "\n",
       "## üë®‚Äçüíª Professional Summary\n",
       "\n",
       "I'm Andrej, a passionate AI researcher and developer specializing in deep learning and neural networks. With a strong foundation in computer science from Stanford, I focus on creating efficient implementations of cutting-edge algorithms using C, CUDA, and Python. My goal is to push the boundaries of machine learning, enabling developers and researchers to leverage powerful tools for training and deploying large language models.\n",
       "\n",
       "## üöÄ Career Objectives\n",
       "\n",
       "I aim to further my expertise in deep learning, particularly in the development of scalable machine learning frameworks and optimization of neural network training processes. I seek a dynamic role in a tech company where I can contribute to innovative projects, collaborate with talented professionals, and continue learning in a challenging environment.\n",
       "\n",
       "## üíª Core Technical Competencies\n",
       "\n",
       "- **Programming Languages**: C, C++, Python, JavaScript\n",
       "- **Frameworks & Libraries**: CUDA, PyTorch, Jupyter Notebook\n",
       "- **Machine Learning & AI**: Deep Learning, Convolutional Neural Networks (CNNs), Natural Language Processing (NLP)\n",
       "- **Software Development**: Version Control (Git), Continuous Integration/Continuous Deployment (CI/CD)\n",
       "- **Tools & Technologies**: Docker, TensorFlow, OpenMPI, NCCL\n",
       "\n",
       "## üåü Notable Projects & Achievements\n",
       "\n",
       "### 1. [llm.c](https://github.com/karpathy/llm.c)\n",
       "A lightweight library for training large language models in pure C/CUDA. This project focuses on reproducing the GPT-2 and GPT-3 models with minimal dependencies, achieving faster training times compared to some mainstream frameworks by optimizing performance with low-level implementations.\n",
       "\n",
       "### 2. [nanoGPT](https://github.com/karpathy/nanoGPT)\n",
       "The simplest, fastest repository for training and fine-tuning medium-sized GPT models. This project emphasizes ease of use and educational content, providing clear examples and structured guidance for aspiring researchers.\n",
       "\n",
       "### 3. [micrograd](https://github.com/karpathy/micrograd)\n",
       "A minimalistic scalar-valued autograd engine that serves as a foundational component for building neural networks. This project showcases my capability to construct fundamental tools that underlie more complex AI applications.\n",
       "\n",
       "### 4. [convnetjs](https://github.com/karpathy/convnetjs)\n",
       "A JavaScript library for running deep learning models in the browser. This project democratizes access to deep learning by allowing developers to carry out computations directly in web applications.\n",
       "\n",
       "### 5. [cryptos](https://github.com/karpathy/cryptos)\n",
       "A pure Python implementation of Bitcoin for educational purposes. This project illustrates my desire to simplify complex concepts to aid learning within the open-source community.\n",
       "\n",
       "## üìà Professional Interests & Development Focus\n",
       "\n",
       "My primary interests lie in the fields of:\n",
       "- **Deep Learning**: Experimenting with novel architectures and large models.\n",
       "- **Optimizations**: Enhancing computational efficiency of existing algorithms.\n",
       "- **Education**: Developing resources and tutorials to assist newcomers to machine learning.\n",
       "- **Open Source Contributions**: Supporting and contributing to diverse projects in the AI and software engineering ecosystem.\n",
       "\n",
       "## ‚úâÔ∏è Professional Contact Methods\n",
       "\n",
       "- **GitHub**: [github.com/karpathy](https://github.com/karpathy)\n",
       "- **Twitter**: [@karpathy](https://twitter.com/karpathy)\n",
       "- **Email**: [andrej@example.com](mailto:andrej@example.com) *(replace with actual email if needed)*\n",
       "\n",
       "---\n",
       "\n",
       "Thank you for viewing my portfolio! I'm excited about the potential for collaboration and am eager to contribute to innovative projects in deep learning and artificial intelligence. Let's connect!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_portfolio(\"https://github.com/karpathy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
